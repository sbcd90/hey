// Code generated by protoc-gen-gogo. DO NOT EDIT.
// source: tensorflow/core/framework/tensor.proto

package tensorflow

import proto "github.com/gogo/protobuf/proto"
import fmt "fmt"
import math "math"

import binary "encoding/binary"

import io "io"

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// Protocol buffer representing a tensor.
type TensorProto struct {
	Dtype DataType `protobuf:"varint,1,opt,name=dtype,proto3,enum=tensorflow.DataType" json:"dtype,omitempty"`
	// Shape of the tensor.  TODO(touts): sort out the 0-rank issues.
	TensorShape *TensorShapeProto `protobuf:"bytes,2,opt,name=tensor_shape,json=tensorShape" json:"tensor_shape,omitempty"`
	// Version number.
	//
	// In version 0, if the "repeated xxx" representations contain only one
	// element, that element is repeated to fill the shape.  This makes it easy
	// to represent a constant Tensor with a single value.
	VersionNumber int32 `protobuf:"varint,3,opt,name=version_number,json=versionNumber,proto3" json:"version_number,omitempty"`
	// Serialized raw tensor content from either Tensor::AsProtoTensorContent or
	// memcpy in tensorflow::grpc::EncodeTensorToByteBuffer. This representation
	// can be used for all tensor types. The purpose of this representation is to
	// reduce serialization overhead during RPC call by avoiding serialization of
	// many repeated small items.
	TensorContent []byte `protobuf:"bytes,4,opt,name=tensor_content,json=tensorContent,proto3" json:"tensor_content,omitempty"`
	// DT_HALF. Note that since protobuf has no int16 type, we'll have some
	// pointless zero padding for each value here.
	HalfVal []int32 `protobuf:"varint,13,rep,packed,name=half_val,json=halfVal" json:"half_val,omitempty"`
	// DT_FLOAT.
	FloatVal []float32 `protobuf:"fixed32,5,rep,packed,name=float_val,json=floatVal" json:"float_val,omitempty"`
	// DT_DOUBLE.
	DoubleVal []float64 `protobuf:"fixed64,6,rep,packed,name=double_val,json=doubleVal" json:"double_val,omitempty"`
	// DT_INT32, DT_INT16, DT_INT8, DT_UINT8.
	IntVal []int32 `protobuf:"varint,7,rep,packed,name=int_val,json=intVal" json:"int_val,omitempty"`
	// DT_STRING
	StringVal [][]byte `protobuf:"bytes,8,rep,name=string_val,json=stringVal" json:"string_val,omitempty"`
	// DT_COMPLEX64. scomplex_val(2*i) and scomplex_val(2*i+1) are real
	// and imaginary parts of i-th single precision complex.
	ScomplexVal []float32 `protobuf:"fixed32,9,rep,packed,name=scomplex_val,json=scomplexVal" json:"scomplex_val,omitempty"`
	// DT_INT64
	Int64Val []int64 `protobuf:"varint,10,rep,packed,name=int64_val,json=int64Val" json:"int64_val,omitempty"`
	// DT_BOOL
	BoolVal []bool `protobuf:"varint,11,rep,packed,name=bool_val,json=boolVal" json:"bool_val,omitempty"`
	// DT_COMPLEX128. dcomplex_val(2*i) and dcomplex_val(2*i+1) are real
	// and imaginary parts of i-th double precision complex.
	DcomplexVal []float64 `protobuf:"fixed64,12,rep,packed,name=dcomplex_val,json=dcomplexVal" json:"dcomplex_val,omitempty"`
	// DT_RESOURCE
	ResourceHandleVal []*ResourceHandleProto `protobuf:"bytes,14,rep,name=resource_handle_val,json=resourceHandleVal" json:"resource_handle_val,omitempty"`
	// DT_VARIANT
	VariantVal []*VariantTensorDataProto `protobuf:"bytes,15,rep,name=variant_val,json=variantVal" json:"variant_val,omitempty"`
}

func (m *TensorProto) Reset()                    { *m = TensorProto{} }
func (m *TensorProto) String() string            { return proto.CompactTextString(m) }
func (*TensorProto) ProtoMessage()               {}
func (*TensorProto) Descriptor() ([]byte, []int) { return fileDescriptorTensor, []int{0} }

func (m *TensorProto) GetDtype() DataType {
	if m != nil {
		return m.Dtype
	}
	return DataType_DT_INVALID
}

func (m *TensorProto) GetTensorShape() *TensorShapeProto {
	if m != nil {
		return m.TensorShape
	}
	return nil
}

func (m *TensorProto) GetVersionNumber() int32 {
	if m != nil {
		return m.VersionNumber
	}
	return 0
}

func (m *TensorProto) GetTensorContent() []byte {
	if m != nil {
		return m.TensorContent
	}
	return nil
}

func (m *TensorProto) GetHalfVal() []int32 {
	if m != nil {
		return m.HalfVal
	}
	return nil
}

func (m *TensorProto) GetFloatVal() []float32 {
	if m != nil {
		return m.FloatVal
	}
	return nil
}

func (m *TensorProto) GetDoubleVal() []float64 {
	if m != nil {
		return m.DoubleVal
	}
	return nil
}

func (m *TensorProto) GetIntVal() []int32 {
	if m != nil {
		return m.IntVal
	}
	return nil
}

func (m *TensorProto) GetStringVal() [][]byte {
	if m != nil {
		return m.StringVal
	}
	return nil
}

func (m *TensorProto) GetScomplexVal() []float32 {
	if m != nil {
		return m.ScomplexVal
	}
	return nil
}

func (m *TensorProto) GetInt64Val() []int64 {
	if m != nil {
		return m.Int64Val
	}
	return nil
}

func (m *TensorProto) GetBoolVal() []bool {
	if m != nil {
		return m.BoolVal
	}
	return nil
}

func (m *TensorProto) GetDcomplexVal() []float64 {
	if m != nil {
		return m.DcomplexVal
	}
	return nil
}

func (m *TensorProto) GetResourceHandleVal() []*ResourceHandleProto {
	if m != nil {
		return m.ResourceHandleVal
	}
	return nil
}

func (m *TensorProto) GetVariantVal() []*VariantTensorDataProto {
	if m != nil {
		return m.VariantVal
	}
	return nil
}

// Protocol buffer representing the serialization format of DT_VARIANT tensors.
type VariantTensorDataProto struct {
	// Name of the type of objects being serialized.
	TypeName string `protobuf:"bytes,1,opt,name=type_name,json=typeName,proto3" json:"type_name,omitempty"`
	// Portions of the object that are not Tensors.
	Metadata []byte `protobuf:"bytes,2,opt,name=metadata,proto3" json:"metadata,omitempty"`
	// Tensors contained within objects being serialized.
	Tensors []*TensorProto `protobuf:"bytes,3,rep,name=tensors" json:"tensors,omitempty"`
}

func (m *VariantTensorDataProto) Reset()                    { *m = VariantTensorDataProto{} }
func (m *VariantTensorDataProto) String() string            { return proto.CompactTextString(m) }
func (*VariantTensorDataProto) ProtoMessage()               {}
func (*VariantTensorDataProto) Descriptor() ([]byte, []int) { return fileDescriptorTensor, []int{1} }

func (m *VariantTensorDataProto) GetTypeName() string {
	if m != nil {
		return m.TypeName
	}
	return ""
}

func (m *VariantTensorDataProto) GetMetadata() []byte {
	if m != nil {
		return m.Metadata
	}
	return nil
}

func (m *VariantTensorDataProto) GetTensors() []*TensorProto {
	if m != nil {
		return m.Tensors
	}
	return nil
}

func init() {
	proto.RegisterType((*TensorProto)(nil), "tensorflow.TensorProto")
	proto.RegisterType((*VariantTensorDataProto)(nil), "tensorflow.VariantTensorDataProto")
}
func (m *TensorProto) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *TensorProto) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.Dtype != 0 {
		dAtA[i] = 0x8
		i++
		i = encodeVarintTensor(dAtA, i, uint64(m.Dtype))
	}
	if m.TensorShape != nil {
		dAtA[i] = 0x12
		i++
		i = encodeVarintTensor(dAtA, i, uint64(m.TensorShape.Size()))
		n1, err := m.TensorShape.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n1
	}
	if m.VersionNumber != 0 {
		dAtA[i] = 0x18
		i++
		i = encodeVarintTensor(dAtA, i, uint64(m.VersionNumber))
	}
	if len(m.TensorContent) > 0 {
		dAtA[i] = 0x22
		i++
		i = encodeVarintTensor(dAtA, i, uint64(len(m.TensorContent)))
		i += copy(dAtA[i:], m.TensorContent)
	}
	if len(m.FloatVal) > 0 {
		dAtA[i] = 0x2a
		i++
		i = encodeVarintTensor(dAtA, i, uint64(len(m.FloatVal)*4))
		for _, num := range m.FloatVal {
			f2 := math.Float32bits(float32(num))
			binary.LittleEndian.PutUint32(dAtA[i:], uint32(f2))
			i += 4
		}
	}
	if len(m.DoubleVal) > 0 {
		dAtA[i] = 0x32
		i++
		i = encodeVarintTensor(dAtA, i, uint64(len(m.DoubleVal)*8))
		for _, num := range m.DoubleVal {
			f3 := math.Float64bits(float64(num))
			binary.LittleEndian.PutUint64(dAtA[i:], uint64(f3))
			i += 8
		}
	}
	if len(m.IntVal) > 0 {
		dAtA5 := make([]byte, len(m.IntVal)*10)
		var j4 int
		for _, num1 := range m.IntVal {
			num := uint64(num1)
			for num >= 1<<7 {
				dAtA5[j4] = uint8(uint64(num)&0x7f | 0x80)
				num >>= 7
				j4++
			}
			dAtA5[j4] = uint8(num)
			j4++
		}
		dAtA[i] = 0x3a
		i++
		i = encodeVarintTensor(dAtA, i, uint64(j4))
		i += copy(dAtA[i:], dAtA5[:j4])
	}
	if len(m.StringVal) > 0 {
		for _, b := range m.StringVal {
			dAtA[i] = 0x42
			i++
			i = encodeVarintTensor(dAtA, i, uint64(len(b)))
			i += copy(dAtA[i:], b)
		}
	}
	if len(m.ScomplexVal) > 0 {
		dAtA[i] = 0x4a
		i++
		i = encodeVarintTensor(dAtA, i, uint64(len(m.ScomplexVal)*4))
		for _, num := range m.ScomplexVal {
			f6 := math.Float32bits(float32(num))
			binary.LittleEndian.PutUint32(dAtA[i:], uint32(f6))
			i += 4
		}
	}
	if len(m.Int64Val) > 0 {
		dAtA8 := make([]byte, len(m.Int64Val)*10)
		var j7 int
		for _, num1 := range m.Int64Val {
			num := uint64(num1)
			for num >= 1<<7 {
				dAtA8[j7] = uint8(uint64(num)&0x7f | 0x80)
				num >>= 7
				j7++
			}
			dAtA8[j7] = uint8(num)
			j7++
		}
		dAtA[i] = 0x52
		i++
		i = encodeVarintTensor(dAtA, i, uint64(j7))
		i += copy(dAtA[i:], dAtA8[:j7])
	}
	if len(m.BoolVal) > 0 {
		dAtA[i] = 0x5a
		i++
		i = encodeVarintTensor(dAtA, i, uint64(len(m.BoolVal)))
		for _, b := range m.BoolVal {
			if b {
				dAtA[i] = 1
			} else {
				dAtA[i] = 0
			}
			i++
		}
	}
	if len(m.DcomplexVal) > 0 {
		dAtA[i] = 0x62
		i++
		i = encodeVarintTensor(dAtA, i, uint64(len(m.DcomplexVal)*8))
		for _, num := range m.DcomplexVal {
			f9 := math.Float64bits(float64(num))
			binary.LittleEndian.PutUint64(dAtA[i:], uint64(f9))
			i += 8
		}
	}
	if len(m.HalfVal) > 0 {
		dAtA11 := make([]byte, len(m.HalfVal)*10)
		var j10 int
		for _, num1 := range m.HalfVal {
			num := uint64(num1)
			for num >= 1<<7 {
				dAtA11[j10] = uint8(uint64(num)&0x7f | 0x80)
				num >>= 7
				j10++
			}
			dAtA11[j10] = uint8(num)
			j10++
		}
		dAtA[i] = 0x6a
		i++
		i = encodeVarintTensor(dAtA, i, uint64(j10))
		i += copy(dAtA[i:], dAtA11[:j10])
	}
	if len(m.ResourceHandleVal) > 0 {
		for _, msg := range m.ResourceHandleVal {
			dAtA[i] = 0x72
			i++
			i = encodeVarintTensor(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	if len(m.VariantVal) > 0 {
		for _, msg := range m.VariantVal {
			dAtA[i] = 0x7a
			i++
			i = encodeVarintTensor(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	return i, nil
}

func (m *VariantTensorDataProto) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *VariantTensorDataProto) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if len(m.TypeName) > 0 {
		dAtA[i] = 0xa
		i++
		i = encodeVarintTensor(dAtA, i, uint64(len(m.TypeName)))
		i += copy(dAtA[i:], m.TypeName)
	}
	if len(m.Metadata) > 0 {
		dAtA[i] = 0x12
		i++
		i = encodeVarintTensor(dAtA, i, uint64(len(m.Metadata)))
		i += copy(dAtA[i:], m.Metadata)
	}
	if len(m.Tensors) > 0 {
		for _, msg := range m.Tensors {
			dAtA[i] = 0x1a
			i++
			i = encodeVarintTensor(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	return i, nil
}

func encodeVarintTensor(dAtA []byte, offset int, v uint64) int {
	for v >= 1<<7 {
		dAtA[offset] = uint8(v&0x7f | 0x80)
		v >>= 7
		offset++
	}
	dAtA[offset] = uint8(v)
	return offset + 1
}
func (m *TensorProto) Size() (n int) {
	var l int
	_ = l
	if m.Dtype != 0 {
		n += 1 + sovTensor(uint64(m.Dtype))
	}
	if m.TensorShape != nil {
		l = m.TensorShape.Size()
		n += 1 + l + sovTensor(uint64(l))
	}
	if m.VersionNumber != 0 {
		n += 1 + sovTensor(uint64(m.VersionNumber))
	}
	l = len(m.TensorContent)
	if l > 0 {
		n += 1 + l + sovTensor(uint64(l))
	}
	if len(m.FloatVal) > 0 {
		n += 1 + sovTensor(uint64(len(m.FloatVal)*4)) + len(m.FloatVal)*4
	}
	if len(m.DoubleVal) > 0 {
		n += 1 + sovTensor(uint64(len(m.DoubleVal)*8)) + len(m.DoubleVal)*8
	}
	if len(m.IntVal) > 0 {
		l = 0
		for _, e := range m.IntVal {
			l += sovTensor(uint64(e))
		}
		n += 1 + sovTensor(uint64(l)) + l
	}
	if len(m.StringVal) > 0 {
		for _, b := range m.StringVal {
			l = len(b)
			n += 1 + l + sovTensor(uint64(l))
		}
	}
	if len(m.ScomplexVal) > 0 {
		n += 1 + sovTensor(uint64(len(m.ScomplexVal)*4)) + len(m.ScomplexVal)*4
	}
	if len(m.Int64Val) > 0 {
		l = 0
		for _, e := range m.Int64Val {
			l += sovTensor(uint64(e))
		}
		n += 1 + sovTensor(uint64(l)) + l
	}
	if len(m.BoolVal) > 0 {
		n += 1 + sovTensor(uint64(len(m.BoolVal))) + len(m.BoolVal)*1
	}
	if len(m.DcomplexVal) > 0 {
		n += 1 + sovTensor(uint64(len(m.DcomplexVal)*8)) + len(m.DcomplexVal)*8
	}
	if len(m.HalfVal) > 0 {
		l = 0
		for _, e := range m.HalfVal {
			l += sovTensor(uint64(e))
		}
		n += 1 + sovTensor(uint64(l)) + l
	}
	if len(m.ResourceHandleVal) > 0 {
		for _, e := range m.ResourceHandleVal {
			l = e.Size()
			n += 1 + l + sovTensor(uint64(l))
		}
	}
	if len(m.VariantVal) > 0 {
		for _, e := range m.VariantVal {
			l = e.Size()
			n += 1 + l + sovTensor(uint64(l))
		}
	}
	return n
}

func (m *VariantTensorDataProto) Size() (n int) {
	var l int
	_ = l
	l = len(m.TypeName)
	if l > 0 {
		n += 1 + l + sovTensor(uint64(l))
	}
	l = len(m.Metadata)
	if l > 0 {
		n += 1 + l + sovTensor(uint64(l))
	}
	if len(m.Tensors) > 0 {
		for _, e := range m.Tensors {
			l = e.Size()
			n += 1 + l + sovTensor(uint64(l))
		}
	}
	return n
}

func sovTensor(x uint64) (n int) {
	for {
		n++
		x >>= 7
		if x == 0 {
			break
		}
	}
	return n
}
func sozTensor(x uint64) (n int) {
	return sovTensor(uint64((x << 1) ^ uint64((int64(x) >> 63))))
}
func (m *TensorProto) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowTensor
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: TensorProto: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: TensorProto: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Dtype", wireType)
			}
			m.Dtype = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowTensor
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Dtype |= (DataType(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field TensorShape", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowTensor
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthTensor
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.TensorShape == nil {
				m.TensorShape = &TensorShapeProto{}
			}
			if err := m.TensorShape.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field VersionNumber", wireType)
			}
			m.VersionNumber = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowTensor
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.VersionNumber |= (int32(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 4:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field TensorContent", wireType)
			}
			var byteLen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowTensor
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				byteLen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if byteLen < 0 {
				return ErrInvalidLengthTensor
			}
			postIndex := iNdEx + byteLen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.TensorContent = append(m.TensorContent[:0], dAtA[iNdEx:postIndex]...)
			if m.TensorContent == nil {
				m.TensorContent = []byte{}
			}
			iNdEx = postIndex
		case 5:
			if wireType == 5 {
				var v uint32
				if (iNdEx + 4) > l {
					return io.ErrUnexpectedEOF
				}
				v = uint32(binary.LittleEndian.Uint32(dAtA[iNdEx:]))
				iNdEx += 4
				v2 := float32(math.Float32frombits(v))
				m.FloatVal = append(m.FloatVal, v2)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowTensor
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthTensor
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v uint32
					if (iNdEx + 4) > l {
						return io.ErrUnexpectedEOF
					}
					v = uint32(binary.LittleEndian.Uint32(dAtA[iNdEx:]))
					iNdEx += 4
					v2 := float32(math.Float32frombits(v))
					m.FloatVal = append(m.FloatVal, v2)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field FloatVal", wireType)
			}
		case 6:
			if wireType == 1 {
				var v uint64
				if (iNdEx + 8) > l {
					return io.ErrUnexpectedEOF
				}
				v = uint64(binary.LittleEndian.Uint64(dAtA[iNdEx:]))
				iNdEx += 8
				v2 := float64(math.Float64frombits(v))
				m.DoubleVal = append(m.DoubleVal, v2)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowTensor
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthTensor
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v uint64
					if (iNdEx + 8) > l {
						return io.ErrUnexpectedEOF
					}
					v = uint64(binary.LittleEndian.Uint64(dAtA[iNdEx:]))
					iNdEx += 8
					v2 := float64(math.Float64frombits(v))
					m.DoubleVal = append(m.DoubleVal, v2)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field DoubleVal", wireType)
			}
		case 7:
			if wireType == 0 {
				var v int32
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowTensor
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= (int32(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.IntVal = append(m.IntVal, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowTensor
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthTensor
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v int32
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowTensor
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= (int32(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.IntVal = append(m.IntVal, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field IntVal", wireType)
			}
		case 8:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field StringVal", wireType)
			}
			var byteLen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowTensor
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				byteLen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if byteLen < 0 {
				return ErrInvalidLengthTensor
			}
			postIndex := iNdEx + byteLen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.StringVal = append(m.StringVal, make([]byte, postIndex-iNdEx))
			copy(m.StringVal[len(m.StringVal)-1], dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 9:
			if wireType == 5 {
				var v uint32
				if (iNdEx + 4) > l {
					return io.ErrUnexpectedEOF
				}
				v = uint32(binary.LittleEndian.Uint32(dAtA[iNdEx:]))
				iNdEx += 4
				v2 := float32(math.Float32frombits(v))
				m.ScomplexVal = append(m.ScomplexVal, v2)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowTensor
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthTensor
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v uint32
					if (iNdEx + 4) > l {
						return io.ErrUnexpectedEOF
					}
					v = uint32(binary.LittleEndian.Uint32(dAtA[iNdEx:]))
					iNdEx += 4
					v2 := float32(math.Float32frombits(v))
					m.ScomplexVal = append(m.ScomplexVal, v2)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field ScomplexVal", wireType)
			}
		case 10:
			if wireType == 0 {
				var v int64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowTensor
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= (int64(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.Int64Val = append(m.Int64Val, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowTensor
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthTensor
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v int64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowTensor
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= (int64(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.Int64Val = append(m.Int64Val, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field Int64Val", wireType)
			}
		case 11:
			if wireType == 0 {
				var v int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowTensor
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.BoolVal = append(m.BoolVal, bool(v != 0))
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowTensor
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthTensor
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v int
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowTensor
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= (int(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.BoolVal = append(m.BoolVal, bool(v != 0))
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field BoolVal", wireType)
			}
		case 12:
			if wireType == 1 {
				var v uint64
				if (iNdEx + 8) > l {
					return io.ErrUnexpectedEOF
				}
				v = uint64(binary.LittleEndian.Uint64(dAtA[iNdEx:]))
				iNdEx += 8
				v2 := float64(math.Float64frombits(v))
				m.DcomplexVal = append(m.DcomplexVal, v2)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowTensor
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthTensor
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v uint64
					if (iNdEx + 8) > l {
						return io.ErrUnexpectedEOF
					}
					v = uint64(binary.LittleEndian.Uint64(dAtA[iNdEx:]))
					iNdEx += 8
					v2 := float64(math.Float64frombits(v))
					m.DcomplexVal = append(m.DcomplexVal, v2)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field DcomplexVal", wireType)
			}
		case 13:
			if wireType == 0 {
				var v int32
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowTensor
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= (int32(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.HalfVal = append(m.HalfVal, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowTensor
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthTensor
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v int32
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowTensor
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= (int32(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.HalfVal = append(m.HalfVal, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field HalfVal", wireType)
			}
		case 14:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ResourceHandleVal", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowTensor
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthTensor
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.ResourceHandleVal = append(m.ResourceHandleVal, &ResourceHandleProto{})
			if err := m.ResourceHandleVal[len(m.ResourceHandleVal)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 15:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field VariantVal", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowTensor
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthTensor
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.VariantVal = append(m.VariantVal, &VariantTensorDataProto{})
			if err := m.VariantVal[len(m.VariantVal)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipTensor(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthTensor
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *VariantTensorDataProto) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowTensor
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: VariantTensorDataProto: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: VariantTensorDataProto: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field TypeName", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowTensor
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthTensor
			}
			postIndex := iNdEx + intStringLen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.TypeName = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Metadata", wireType)
			}
			var byteLen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowTensor
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				byteLen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if byteLen < 0 {
				return ErrInvalidLengthTensor
			}
			postIndex := iNdEx + byteLen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Metadata = append(m.Metadata[:0], dAtA[iNdEx:postIndex]...)
			if m.Metadata == nil {
				m.Metadata = []byte{}
			}
			iNdEx = postIndex
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Tensors", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowTensor
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthTensor
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Tensors = append(m.Tensors, &TensorProto{})
			if err := m.Tensors[len(m.Tensors)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipTensor(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthTensor
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func skipTensor(dAtA []byte) (n int, err error) {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return 0, ErrIntOverflowTensor
			}
			if iNdEx >= l {
				return 0, io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		wireType := int(wire & 0x7)
		switch wireType {
		case 0:
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return 0, ErrIntOverflowTensor
				}
				if iNdEx >= l {
					return 0, io.ErrUnexpectedEOF
				}
				iNdEx++
				if dAtA[iNdEx-1] < 0x80 {
					break
				}
			}
			return iNdEx, nil
		case 1:
			iNdEx += 8
			return iNdEx, nil
		case 2:
			var length int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return 0, ErrIntOverflowTensor
				}
				if iNdEx >= l {
					return 0, io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				length |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			iNdEx += length
			if length < 0 {
				return 0, ErrInvalidLengthTensor
			}
			return iNdEx, nil
		case 3:
			for {
				var innerWire uint64
				var start int = iNdEx
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return 0, ErrIntOverflowTensor
					}
					if iNdEx >= l {
						return 0, io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					innerWire |= (uint64(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				innerWireType := int(innerWire & 0x7)
				if innerWireType == 4 {
					break
				}
				next, err := skipTensor(dAtA[start:])
				if err != nil {
					return 0, err
				}
				iNdEx = start + next
			}
			return iNdEx, nil
		case 4:
			return iNdEx, nil
		case 5:
			iNdEx += 4
			return iNdEx, nil
		default:
			return 0, fmt.Errorf("proto: illegal wireType %d", wireType)
		}
	}
	panic("unreachable")
}

var (
	ErrInvalidLengthTensor = fmt.Errorf("proto: negative length found during unmarshaling")
	ErrIntOverflowTensor   = fmt.Errorf("proto: integer overflow")
)

func init() { proto.RegisterFile("tensorflow/core/framework/tensor.proto", fileDescriptorTensor) }

var fileDescriptorTensor = []byte{
	// 535 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0x84, 0x93, 0x4f, 0xaf, 0xd2, 0x4c,
	0x14, 0xc6, 0x33, 0xf4, 0x05, 0xda, 0xd3, 0xc2, 0xab, 0xd5, 0x68, 0xc3, 0xf5, 0x42, 0x25, 0xc1,
	0x34, 0xc6, 0x40, 0x44, 0x63, 0xe2, 0xca, 0x84, 0xeb, 0xc2, 0xd5, 0xf5, 0xa6, 0xde, 0xb0, 0x25,
	0x03, 0x1d, 0x2e, 0x8d, 0xed, 0x0c, 0x99, 0x0e, 0x5c, 0xef, 0xde, 0x9d, 0x5f, 0xcc, 0xa5, 0x1f,
	0xc1, 0xf0, 0x29, 0x5c, 0x9a, 0x39, 0x53, 0xa0, 0xfe, 0x5f, 0xf6, 0x79, 0x7e, 0xe7, 0x39, 0x67,
	0x3a, 0x67, 0xe0, 0x91, 0x62, 0xbc, 0x10, 0x72, 0x99, 0x89, 0xeb, 0xd1, 0x42, 0x48, 0x36, 0x5a,
	0x4a, 0x9a, 0xb3, 0x6b, 0x21, 0xdf, 0x8f, 0x8c, 0x33, 0x5c, 0x4b, 0xa1, 0x84, 0x0f, 0x47, 0xae,
	0x33, 0xfa, 0x73, 0x8d, 0x64, 0x85, 0xd8, 0xc8, 0x05, 0x9b, 0xad, 0x28, 0x4f, 0x32, 0x66, 0x8a,
	0x3b, 0x4f, 0xfe, 0xd5, 0x64, 0x56, 0xac, 0xe8, 0x7a, 0x4f, 0x0f, 0xfe, 0x42, 0xdf, 0xac, 0x59,
	0x61, 0xb0, 0xfe, 0xa7, 0x3a, 0xb8, 0x97, 0x48, 0x5e, 0xe0, 0x84, 0x8f, 0xa1, 0x9e, 0x68, 0x3f,
	0x20, 0x21, 0x89, 0xda, 0xe3, 0xbb, 0xc3, 0x63, 0xcc, 0xf0, 0x35, 0x55, 0xf4, 0xf2, 0x66, 0xcd,
	0x62, 0x83, 0xf8, 0xaf, 0xc0, 0xab, 0x36, 0x0e, 0x6a, 0x21, 0x89, 0xdc, 0xf1, 0x83, 0x6a, 0x89,
	0x89, 0x7e, 0xa7, 0x6d, 0xcc, 0x8f, 0x5d, 0x75, 0x54, 0xfc, 0x01, 0xb4, 0xb7, 0x4c, 0x16, 0xa9,
	0xe0, 0x33, 0xbe, 0xc9, 0xe7, 0x4c, 0x06, 0x56, 0x48, 0xa2, 0x7a, 0xdc, 0x2a, 0xd5, 0x73, 0x14,
	0x35, 0x56, 0xf6, 0x59, 0x08, 0xae, 0x18, 0x57, 0xc1, 0x7f, 0x21, 0x89, 0xbc, 0xb8, 0x65, 0xd4,
	0x33, 0x23, 0xfa, 0x3d, 0x70, 0x96, 0x99, 0xa0, 0x6a, 0xb6, 0xa5, 0x59, 0x50, 0x0f, 0xad, 0xa8,
	0x36, 0xa9, 0xdd, 0x22, 0xb1, 0x8d, 0xe2, 0x94, 0x66, 0xfe, 0x43, 0x80, 0x44, 0x6c, 0xe6, 0x19,
	0x43, 0xa2, 0x11, 0x5a, 0x11, 0x41, 0xc2, 0x31, 0xaa, 0x46, 0x4e, 0xa0, 0x99, 0x72, 0x93, 0xd0,
	0x0c, 0xad, 0xa8, 0x8e, 0x7e, 0x23, 0xe5, 0x58, 0x7f, 0x0a, 0x50, 0x28, 0x99, 0xf2, 0x2b, 0xf4,
	0xed, 0xd0, 0x8a, 0xbc, 0xd8, 0x31, 0x8a, 0xb6, 0x07, 0xe0, 0x15, 0x0b, 0x91, 0xaf, 0x33, 0xf6,
	0x01, 0x01, 0xe7, 0x30, 0x82, 0xbb, 0xd7, 0x35, 0xd6, 0x03, 0x27, 0xe5, 0xea, 0xc5, 0x73, 0x64,
	0x20, 0xb4, 0x22, 0xcb, 0x8c, 0x89, 0xa2, 0x69, 0x63, 0xcf, 0x85, 0xc8, 0xd0, 0x77, 0x43, 0x2b,
	0xb2, 0xd1, 0x6f, 0x6a, 0xad, 0x6c, 0x93, 0x54, 0xdb, 0x78, 0x87, 0x73, 0xb8, 0x49, 0xa5, 0xcd,
	0x29, 0xd8, 0x2b, 0x9a, 0x2d, 0x11, 0x69, 0x1d, 0x8e, 0xd2, 0xd4, 0x9a, 0xb6, 0xdf, 0xc2, 0x9d,
	0x9f, 0xb6, 0x0c, 0xc9, 0x76, 0x68, 0x45, 0xee, 0xb8, 0x57, 0xbd, 0xc2, 0xb8, 0xc4, 0xde, 0x20,
	0x65, 0x6e, 0xf1, 0xb6, 0xfc, 0x41, 0xd4, 0x81, 0x67, 0xe0, 0x6e, 0xa9, 0x4c, 0x69, 0xf9, 0xf7,
	0xfe, 0xc7, 0xa0, 0x7e, 0x35, 0x68, 0x6a, 0x6c, 0xb3, 0x12, 0x7a, 0x97, 0x4c, 0x16, 0x94, 0x65,
	0x53, 0x9a, 0xf5, 0x3f, 0x12, 0xb8, 0xf7, 0x7b, 0xcc, 0x3f, 0x01, 0x47, 0x2f, 0xdd, 0x8c, 0xd3,
	0xdc, 0x2c, 0xa7, 0x13, 0xdb, 0x5a, 0x38, 0xa7, 0x39, 0xf3, 0x3b, 0x60, 0xe7, 0x4c, 0xd1, 0x84,
	0x2a, 0x8a, 0x5b, 0xe8, 0xc5, 0x87, 0x6f, 0xff, 0x29, 0x34, 0xcd, 0x10, 0x45, 0x60, 0xe1, 0x50,
	0xf7, 0x7f, 0x5d, 0x50, 0x33, 0xc9, 0x9e, 0x9b, 0xbc, 0xfc, 0xbc, 0xeb, 0x92, 0x2f, 0xbb, 0x2e,
	0xf9, 0xba, 0xeb, 0x12, 0x08, 0x84, 0xbc, 0xaa, 0x96, 0x1c, 0x1e, 0xd2, 0xc4, 0xab, 0x54, 0x17,
	0x17, 0xe4, 0x1b, 0x21, 0xf3, 0x06, 0x3e, 0xab, 0x67, 0xdf, 0x03, 0x00, 0x00, 0xff, 0xff, 0x77,
	0xda, 0x73, 0x55, 0x12, 0x04, 0x00, 0x00,
}
